{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, header=None, skiprows=0)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = r\"C:\\Users\\nstep\\TSU\\SeniorProject\\nashvilleDF.csv\"\n",
    "nashvilleDF = load_data(file_path)\n",
    "\n",
    "#nashvilleDf to lower case\n",
    "\n",
    "nashvilleDF.head()\n",
    "\n",
    "#check to see if nashvilleDF has a column named 'id' and show results for 5 rows\n",
    "nashvilleDF['id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "subsetdf = nashvilleDF.dropna()\n",
    "\n",
    "# Define the outcome\n",
    "outcome = 'price'\n",
    "\n",
    "# Store results in a list to maintain order\n",
    "results = []\n",
    "\n",
    "# Initialize the learner using HistGradientBoostingRegressor\n",
    "learner = TLearner(models=HistGradientBoostingRegressor())\n",
    "\n",
    "def get_causal_estimate(treatment):\n",
    "    common_causes = [col for col in subsetdf.columns if col != treatment and col != outcome]\n",
    "\n",
    "    # Create a causal model with your subsetdf\n",
    "    model = CausalModel(\n",
    "        data=subsetdf,\n",
    "        treatment=treatment,\n",
    "        outcome=outcome,\n",
    "        common_causes=common_causes,\n",
    "        logging_level=logging.INFO\n",
    "    )\n",
    "\n",
    "    # Identify the causal effect\n",
    "    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "\n",
    "    # Estimate the causal effect using the T-learner from EconML\n",
    "    causal_estimate = model.estimate_effect(identified_estimand,\n",
    "                                            method_name=\"backdoor.econml.metalearners.TLearner\",\n",
    "                                            control_value=0,\n",
    "                                            treatment_value=1,\n",
    "                                            target_units=\"att\",\n",
    "                                            method_params={\"learner\": learner})\n",
    "    \n",
    "    return {\n",
    "        \"causal_estimate\": causal_estimate.value,\n",
    "        \"treatment\": treatment\n",
    "    }\n",
    "\n",
    "# Parallelize the computation using joblib\n",
    "treatments = [col for col in subsetdf.columns if col != outcome]\n",
    "results = Parallel(n_jobs=-1)(delayed(get_causal_estimate)(treatment) for treatment in treatments)\n",
    "\n",
    "# Sort the results by causal estimate value in descending order\n",
    "sorted_results = sorted(results, key=lambda x: x['causal_estimate'], reverse=True)\n",
    "\n",
    "# Display the top 10 results\n",
    "for result in sorted_results[:10]:\n",
    "    print(f\"Treatment: {result['treatment']}, Causal Estimate: {result['causal_estimate']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
